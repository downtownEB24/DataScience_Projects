{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c6b741",
   "metadata": {},
   "source": [
    "# Text Mining - Natural Language Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80125a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5966b441",
   "metadata": {},
   "source": [
    "Question 1.) Use the following codes to load the assignment12.txt  Download assignment12.txt which contains file names. How many file names in it? (10 points)\n",
    "\n",
    "file = open(\"Assignment_12.txt\" , 'r')\n",
    "text1 = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c42051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of file names in the assignment12.txt file is: 90\n"
     ]
    }
   ],
   "source": [
    "file = open(\"C:/Users/esbro/Desktop/DAAN862/Week 12/Assignment_12.txt\" , 'r')\n",
    "text1 = file.read()\n",
    "file.close()\n",
    "#split the data file text by more than one space\n",
    "distFile=re.split('\\s+',text1)\n",
    "nameCount=len(distFile) #getting the number of file names in the text file\n",
    "print(\"Number of file names in the assignment12.txt file is:\",nameCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5935f2",
   "metadata": {},
   "source": [
    "Question 2.) Identify the pattern of the file names, and find out how many file names match the pattern. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef5ae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of file names that match the pattern created in this code is: 84\n",
      "\n",
      "The file names that match the pattern are:\n",
      "arxiv_annotate10_7_1.txt\n",
      "arxiv_annotate10_7_2.txt\n",
      "arxiv_annotate10_7_3.txt\n",
      "arxiv_annotate1_13_1.txt\n",
      "arxiv_annotate1_13_2.txt\n",
      "arxiv_annotate1_13_3.txt\n",
      "arxiv_annotate2_66_1.txt\n",
      "arxiv_annotate2_66_2.txt\n",
      "arxiv_annotate2_66_3.txt\n",
      "arxiv_annotate3_80_1.txt\n",
      "arxiv_annotate3_80_2.txt\n",
      "arxiv_annotate3_80_3.txt\n",
      "arxiv_annotate4_168_1.txt\n",
      "arxiv_annotate4_168_2.txt\n",
      "arxiv_annotate4_168_3.txt\n",
      "arxiv_annotate5_240_1.txt\n",
      "arxiv_annotate5_240_2.txt\n",
      "arxiv_annotate5_240_3.txt\n",
      "arxiv_annotate6_52_1.txt\n",
      "arxiv_annotate6_52_2.txt\n",
      "arxiv_annotate6_52_3.txt\n",
      "arxiv_annotate7_268_1.txt\n",
      "arxiv_annotate7_268_2.txt\n",
      "arxiv_annotate7_268_3.txt\n",
      "arxiv_annotate8_81_1.txt\n",
      "arxiv_annotate8_81_2.txt\n",
      "arxiv_annotate8_81_3.txt\n",
      "arxiv_annotate9_279_1.txt\n",
      "arxiv_annotate9_279_2.txt\n",
      "arxiv_annotate9_279_3.txt\n",
      "jdm_annotate10_210_1.txt\n",
      "jdm_annotate10_210_2.txt\n",
      "jdm_annotate10_210_3.txt\n",
      "jdm_annotate1_103_1.txt\n",
      "jdm_annotate1_103_2.txt\n",
      "jdm_annotate1_103_3.txt\n",
      "jdm_annotate2_107_1.txt\n",
      "jdm_annotate2_107_2.txt\n",
      "jdm_annotate2_107_3.txt\n",
      "jdm_annotate3_120_2.txt\n",
      "jdm_annotate3_120_3.txt\n",
      "jdm_annotate4_220_1.txt\n",
      "jdm_annotate4_220_2.txt\n",
      "jdm_annotate4_220_3.txt\n",
      "jdm_annotate5_228_1.txt\n",
      "jdm_annotate5_228_2.txt\n",
      "jdm_annotate5_228_3.txt\n",
      "jdm_annotate6_32_1.txt\n",
      "jdm_annotate6_32_3.txt\n",
      "jdm_annotate7_265_1.txt\n",
      "jdm_annotate7_265_2.txt\n",
      "jdm_annotate7_265_3.txt\n",
      "jdm_annotate8_177_1.txt\n",
      "jdm_annotate8_177_3.txt\n",
      "jdm_annotate9_45_1.txt\n",
      "jdm_annotate9_45_2.txt\n",
      "jdm_annotate9_45_3.txt\n",
      "plos_annotate10_1140_1.txt\n",
      "plos_annotate10_1140_2.txt\n",
      "plos_annotate10_1140_3.txt\n",
      "plos_annotate1_6_1.txt\n",
      "plos_annotate1_6_3.txt\n",
      "plos_annotate2_336_1.txt\n",
      "plos_annotate2_336_2.txt\n",
      "plos_annotate2_336_3.txt\n",
      "plos_annotate3_798_1.txt\n",
      "plos_annotate3_798_2.txt\n",
      "plos_annotate3_798_3.txt\n",
      "plos_annotate4_1052_1.txt\n",
      "plos_annotate4_1052_2.txt\n",
      "plos_annotate4_1052_3.txt\n",
      "plos_annotate5_1375_1.txt\n",
      "plos_annotate5_1375_2.txt\n",
      "plos_annotate6_1032_1.txt\n",
      "plos_annotate6_1032_2.txt\n",
      "plos_annotate6_1032_3.txt\n",
      "plos_annotate7_1233_1.txt\n",
      "plos_annotate7_1233_3.txt\n",
      "plos_annotate8_123_1.txt\n",
      "plos_annotate8_123_2.txt\n",
      "plos_annotate8_123_3.txt\n",
      "plos_annotate9_1187_1.txt\n",
      "plos_annotate9_1187_2.txt\n",
      "plos_annotate9_1187_3.txt\n"
     ]
    }
   ],
   "source": [
    "pattern=r'[a-z]+[a-z_0-9]+[_0-9]+[0-9]+\\.[a-z]{3}' #creating raw string to use as regular expression pattern\n",
    "regex=re.compile(pattern)#using re built-in package to compile the pattern created above\n",
    "names=regex.findall(text1) #finding out all the text that match the pattern created above and storing them in a list\n",
    "\n",
    "corrCount=0 #used to get a pattern count on all the file names that match pattern above\n",
    "corrDict={} #used to store the file names that match pattern above\n",
    "\n",
    "#need to iterate through names to see which file names were actually copied correctly from the pattern and matched the pattern\n",
    "for filename in names:\n",
    "#checking to see if file name created from the pattern findall function is actually the same file name in the original text file    \n",
    "        if filename in distFile: \n",
    "            corrCount+=1 #count counter is increase if this condition is satisfied\n",
    "            corrDict[filename]=distFile[names.index(filename)] #for testing purpose to make sure file name is written correctly\n",
    "print(\"The number of file names that match the pattern created in this code is:\",corrCount)  \n",
    "print(\"\\nThe file names that match the pattern are:\")\n",
    "for key,value in corrDict.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc41399",
   "metadata": {},
   "source": [
    "Question 3.) Find out file names who don't match with the pattern you designed. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d663f023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of file names that match the pattern created in this code is: 6\n",
      "\n",
      "The file names that do not match the pattern are:\n",
      "otate3_120_1.txt Correct file name is -> jdm_ann^otate3_120_1.txt\n",
      "tate6_32_2.txt Correct file name is -> jdm_anno&tate6_32_2.txt\n",
      "e8_177_2.txt Correct file name is -> jdm_annotat#e8_177_2.txt\n",
      "e1_6_2.txt Correct file name is -> plos_annotat*e1_6_2.txt\n",
      "tate5_1375_3.txt Correct file name is -> plos_anno%tate5_1375_3.txt\n",
      "ate7_1233_2.txt Correct file name is -> plos_annot@ate7_1233_2.txt\n"
     ]
    }
   ],
   "source": [
    "pattern=r'[a-z]+[a-z_0-9]+[_0-9]+[0-9]+\\.[a-z]{3}'#creating raw string to use as regular expression pattern\n",
    "regex=re.compile(pattern)#using re built-in package to compile the pattern created above\n",
    "names=regex.findall(text1)#finding out all the text that do not match the pattern created above and storing them in a list\n",
    "\n",
    "incCount=0 #used to get a pattern count on all the file names that do not match pattern above\n",
    "incDict={} #used to store the file names that do not match pattern above\n",
    "\n",
    "#need to iterate through names to see which file names were not copied correctly from the pattern and do not matched the pattern\n",
    "for filename in names:\n",
    "#checking to see if file name created from the pattern findall function is not the same file name in the original text file        \n",
    "        if filename not in distFile:\n",
    "            incCount+=1 #count counter is increased if this condition is satisfied\n",
    "            #storing the file names that were not copied correctly from the pattern since they do not match the pattern created\n",
    "            incDict[filename]=distFile[names.index(filename)]\n",
    "            \n",
    "print(\"The number of file names that match the pattern created in this code is:\",incCount)\n",
    "print(\"\\nThe file names that do not match the pattern are:\")\n",
    "for key,value in incDict.items():\n",
    "    print(key,\"Correct file name is ->\",value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaffe33",
   "metadata": {},
   "source": [
    "Question 4.) Use the following codes to read the text from “arxiv_annotate1_13_1.txt  Download arxiv_annotate1_13_1.txt” in\n",
    "\n",
    "file = open(“arxiv_annotate1_13_1.txt”, 'r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "Normalize the words and find out their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a230863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Word  Count\n",
      "0      abstract      1\n",
      "1          MISC     20\n",
      "2      although      1\n",
      "3           the     44\n",
      "4      internet     15\n",
      "..          ...    ...\n",
      "318     specify      1\n",
      "319  experiment      1\n",
      "320  introduces      1\n",
      "321        them      1\n",
      "322    conclude      1\n",
      "\n",
      "[323 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file = open(\"C:/Users/esbro/Desktop/DAAN862/Week 12/arxiv_annotate1_13_1.txt\", 'r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "#using the lemmatization model in nltk to get all root words from the text file\n",
    "lemma=nltk.WordNetLemmatizer()\n",
    "nltk.download('wordnet') #have to download this library for the WordNetLemmatizer to work\n",
    "list1=[] #creating this list to store all words in the text file that are in wordnet database of words \n",
    "\n",
    "#iterating through the words in the text file seperated by spaces,tabs, and newlines\n",
    "for word in re.split(' |\\t|\\n',text):\n",
    "#getting rid of blank characters and special characters that seperate each body of text in the text file\n",
    "    if word not in ['###','']:\n",
    "        list1.append(lemma.lemmatize(word)) #adding each word to the list that meet this condition\n",
    "        \n",
    "#getting unique words and their frequencies from the words list and storing this info in a dictionary      \n",
    "wordFreq=nltk.FreqDist(list1)\n",
    "#creating a dataframe to list out words and their frequencies\n",
    "print(pd.DataFrame(list(wordFreq.items()), columns = [\"Word\",\"Count\"]))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
